{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/komangandikawirasantosa/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Two Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"verified\": false,\n",
      "  \"distance\": 0.8571385339546812,\n",
      "  \"threshold\": 0.68,\n",
      "  \"model\": \"VGG-Face\",\n",
      "  \"detector_backend\": \"opencv\",\n",
      "  \"similarity_metric\": \"cosine\",\n",
      "  \"facial_areas\": {\n",
      "    \"img1\": {\n",
      "      \"x\": 335,\n",
      "      \"y\": 108,\n",
      "      \"w\": 484,\n",
      "      \"h\": 484,\n",
      "      \"left_eye\": [\n",
      "        645,\n",
      "        290\n",
      "      ],\n",
      "      \"right_eye\": [\n",
      "        489,\n",
      "        301\n",
      "      ]\n",
      "    },\n",
      "    \"img2\": {\n",
      "      \"x\": 318,\n",
      "      \"y\": 259,\n",
      "      \"w\": 389,\n",
      "      \"h\": 389,\n",
      "      \"left_eye\": [\n",
      "        579,\n",
      "        401\n",
      "      ],\n",
      "      \"right_eye\": [\n",
      "        423,\n",
      "        395\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"time\": 1.32\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = DeepFace.verify(img1_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/Barron.png\",img2_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/TrumpMew1.png\")\n",
    "print(json.dumps(result,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set Pandas to display the full content without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing 1 image from a database (pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-11 10:29:40 - Searching /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Search.png in 7 length datastore\n",
      "24-10-11 10:29:41 - find function duration 0.8587932586669922 seconds\n",
      "[                                                                      identity  \\\n",
      "0  /Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/TrumpMew2.png   \n",
      "1     /Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/Trump1.png   \n",
      "2     /Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/Trump3.png   \n",
      "\n",
      "                                       hash  target_x  target_y  target_w  \\\n",
      "0  d8baf7c8783018470b47cfb9790eda1407a6aa23       183        93       346   \n",
      "1  f7589797d221e817c885a2abc2f36886a9536853       259       150       368   \n",
      "2  ba519763be81cdaf8ac687940685e5f0ac82db26       430       177       346   \n",
      "\n",
      "   target_h  source_x  source_y  source_w  source_h  threshold  distance  \n",
      "0       346       170        27       682       682       0.68  0.613812  \n",
      "1       368       170        27       682       682       0.68  0.665577  \n",
      "2       346       170        27       682       682       0.68  0.669155  ]\n"
     ]
    }
   ],
   "source": [
    "dfs = DeepFace.find(\n",
    "  img_path = \"/Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Search.png\",\n",
    "  db_path = \"/Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos\",\n",
    ")\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|██████████████▌              | 2/4 [00:02<00:02,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-11 10:29:55 - gender_model_weights.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/gender_model_weights.h5\n",
      "To: /Users/komangandikawirasantosa/.deepface/weights/gender_model_weights.h5\n",
      "100%|█████████████████████████████████████████| 537M/537M [11:16<00:00, 794kB/s]\n",
      "Action: race:  75%|██████████████████████▌       | 3/4 [11:22<05:11, 311.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-11 10:41:16 - race_model_single_batch.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/race_model_single_batch.h5\n",
      "To: /Users/komangandikawirasantosa/.deepface/weights/race_model_single_batch.h5\n",
      "100%|████████████████████████████████████████| 537M/537M [08:29<00:00, 1.05MB/s]\n",
      "Action: race: 100%|██████████████████████████████| 4/4 [19:57<00:00, 299.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"emotion\": {\n",
      "      \"angry\": 33.51637622811653,\n",
      "      \"disgust\": 4.3580137653810107e-07,\n",
      "      \"fear\": 0.2850894753315732,\n",
      "      \"happy\": 3.1951090790195565e-05,\n",
      "      \"sad\": 52.929583366488416,\n",
      "      \"surprise\": 0.00014337358324713128,\n",
      "      \"neutral\": 13.268777028845372\n",
      "    },\n",
      "    \"dominant_emotion\": \"sad\",\n",
      "    \"region\": {\n",
      "      \"x\": 318,\n",
      "      \"y\": 259,\n",
      "      \"w\": 389,\n",
      "      \"h\": 389,\n",
      "      \"left_eye\": [\n",
      "        579,\n",
      "        401\n",
      "      ],\n",
      "      \"right_eye\": [\n",
      "        423,\n",
      "        395\n",
      "      ]\n",
      "    },\n",
      "    \"face_confidence\": 0.93,\n",
      "    \"age\": 24,\n",
      "    \"gender\": {\n",
      "      \"Woman\": 0.002447343103995081,\n",
      "      \"Man\": 99.99755620956421\n",
      "    },\n",
      "    \"dominant_gender\": \"Man\",\n",
      "    \"race\": {\n",
      "      \"asian\": 69.5778704192793,\n",
      "      \"indian\": 3.010650179010608,\n",
      "      \"black\": 1.137457279866066,\n",
      "      \"white\": 17.95490021051166,\n",
      "      \"middle eastern\": 1.7966136057241433,\n",
      "      \"latino hispanic\": 6.522501972615483\n",
      "    },\n",
      "    \"dominant_race\": \"asian\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "objs = DeepFace.analyze(img_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/TrumpMew1.png\")\n",
    "print(json.dumps(objs,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-11 15:52:35 - Age model is just built\n",
      "24-10-11 15:52:37 - Gender model is just built\n",
      "24-10-11 15:52:37 - Emotion model is just built\n",
      "24-10-11 15:52:38 - VGG-Face is built\n",
      "24-10-11 15:52:44 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-11 15:52:48 - freezed\n",
      "24-10-11 15:52:53 - freeze released\n",
      "24-10-11 15:52:56 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi2.JPG\n",
      "24-10-11 15:53:00 - freezed\n",
      "24-10-11 15:53:05 - freeze released\n",
      "24-10-11 15:53:08 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-11 15:53:13 - freezed\n",
      "24-10-11 15:53:18 - freeze released\n",
      "24-10-11 15:53:21 - freezed\n",
      "24-10-11 15:53:26 - freeze released\n",
      "24-10-11 15:53:29 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-11 15:53:34 - freezed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/DeepFace.py:476\u001b[0m, in \u001b[0;36mstream\u001b[0;34m(db_path, model_name, detector_backend, distance_metric, enable_face_analysis, source, time_threshold, frame_threshold, anti_spoofing)\u001b[0m\n\u001b[1;32m    473\u001b[0m time_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(time_threshold, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    474\u001b[0m frame_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(frame_threshold, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 476\u001b[0m \u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_face_analysis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_face_analysis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/modules/streaming.py:86\u001b[0m, in \u001b[0;36manalysis\u001b[0;34m(db_path, model_name, detector_backend, distance_metric, enable_face_analysis, source, time_threshold, frame_threshold, anti_spoofing)\u001b[0m\n\u001b[1;32m     84\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(source)  \u001b[38;5;66;03m# webcam\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     has_frame, img \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_frame:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DeepFace.stream(db_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/komangandikawirasantosa/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-16 15:47:13 - VGG-Face is built\n",
      "24-10-16 15:47:18 - freezed\n",
      "24-10-16 15:47:21 - freeze released\n",
      "24-10-16 15:47:23 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi2.JPG\n",
      "24-10-16 15:47:27 - freezed\n",
      "24-10-16 15:47:30 - freeze released\n",
      "24-10-16 15:47:34 - freezed\n",
      "24-10-16 15:47:37 - freeze released\n",
      "24-10-16 15:47:39 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-16 15:47:44 - freezed\n",
      "24-10-16 15:47:47 - freeze released\n",
      "24-10-16 15:47:49 - freezed\n",
      "24-10-16 15:47:52 - freeze released\n",
      "24-10-16 15:48:07 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-16 15:48:12 - freezed\n",
      "24-10-16 15:48:15 - freeze released\n",
      "24-10-16 15:48:17 - freezed\n",
      "24-10-16 15:48:20 - freeze released\n",
      "24-10-16 15:48:30 - freezed\n",
      "24-10-16 15:48:33 - freeze released\n",
      "24-10-16 15:48:36 - freezed\n",
      "24-10-16 15:48:39 - freeze released\n",
      "24-10-16 15:48:41 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Deci/Deci.jpg\n",
      "24-10-16 15:48:43 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-16 15:48:47 - freezed\n",
      "24-10-16 15:48:50 - freeze released\n",
      "24-10-16 15:48:53 - freezed\n",
      "24-10-16 15:48:56 - freeze released\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[0;32m----> 3\u001b[0m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVGG-Face\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopencv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_face_analysis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default webcam\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/DeepFace.py:476\u001b[0m, in \u001b[0;36mstream\u001b[0;34m(db_path, model_name, detector_backend, distance_metric, enable_face_analysis, source, time_threshold, frame_threshold, anti_spoofing)\u001b[0m\n\u001b[1;32m    473\u001b[0m time_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(time_threshold, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    474\u001b[0m frame_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(frame_threshold, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 476\u001b[0m \u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_face_analysis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_face_analysis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/modules/streaming.py:129\u001b[0m, in \u001b[0;36manalysis\u001b[0;34m(db_path, model_name, detector_backend, distance_metric, enable_face_analysis, source, time_threshold, frame_threshold, anti_spoofing)\u001b[0m\n\u001b[1;32m    122\u001b[0m img \u001b[38;5;241m=\u001b[39m perform_demography_analysis(\n\u001b[1;32m    123\u001b[0m     enable_face_analysis\u001b[38;5;241m=\u001b[39menable_face_analysis,\n\u001b[1;32m    124\u001b[0m     img\u001b[38;5;241m=\u001b[39mraw_img,\n\u001b[1;32m    125\u001b[0m     faces_coordinates\u001b[38;5;241m=\u001b[39mfaces_coordinates,\n\u001b[1;32m    126\u001b[0m     detected_faces\u001b[38;5;241m=\u001b[39mdetected_faces,\n\u001b[1;32m    127\u001b[0m )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# facial recogntion analysis\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mperform_facial_recognition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfaces_coordinates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfaces_coordinates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetected_faces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetected_faces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# freeze the img after analysis\u001b[39;00m\n\u001b[1;32m    140\u001b[0m freezed_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/modules/streaming.py:454\u001b[0m, in \u001b[0;36mperform_facial_recognition\u001b[0;34m(img, detected_faces, faces_coordinates, db_path, detector_backend, distance_metric, model_name)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (x, y, w, h, is_real, antispoof_score) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(faces_coordinates):\n\u001b[1;32m    453\u001b[0m     detected_face \u001b[38;5;241m=\u001b[39m detected_faces[idx]\n\u001b[0;32m--> 454\u001b[0m     target_label, target_img \u001b[38;5;241m=\u001b[39m \u001b[43msearch_identity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetected_face\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetected_face\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/modules/streaming.py:205\u001b[0m, in \u001b[0;36msearch_identity\u001b[0;34m(detected_face, db_path, model_name, detector_backend, distance_metric)\u001b[0m\n\u001b[1;32m    203\u001b[0m target_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetected_face\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo item found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/DeepFace.py:342\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, expand_percentage, threshold, normalization, silent, refresh_database, anti_spoofing)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(\n\u001b[1;32m    266\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    267\u001b[0m     db_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m    280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    Identify individuals in a database\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m                specified model and distance metric\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefresh_database\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh_database\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/modules/recognition.py:267\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, expand_percentage, threshold, normalization, silent, refresh_database, anti_spoofing)\u001b[0m\n\u001b[1;32m    264\u001b[0m target_representation \u001b[38;5;241m=\u001b[39m target_embedding_obj[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    266\u001b[0m result_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# df will be filtered in each img\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m result_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_x\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m source_region[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    268\u001b[0m result_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_y\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m source_region[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    269\u001b[0m result_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_w\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m source_region[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4527\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03mAdd series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03mensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   4526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m-> 4527\u001b[0m     \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m   4528\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m ):\n\u001b[1;32m   4531\u001b[0m     \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[1;32m   4533\u001b[0m         existing_piece \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[key]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5360\u001b[0m, in \u001b[0;36mIndex.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5358\u001b[0m \u001b[38;5;28mhash\u001b[39m(key)\n\u001b[1;32m   5359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   5361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOverflowError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   5362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "DeepFace.stream(\n",
    "    db_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database\",\n",
    "    model_name=\"VGG-Face\",\n",
    "    detector_backend=\"opencv\",\n",
    "    distance_metric=\"cosine\",\n",
    "    enable_face_analysis=False,\n",
    "    source=1,  # default webcam\n",
    "    time_threshold=3,\n",
    "    frame_threshold=5,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
