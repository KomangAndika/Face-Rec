{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/komangandikawirasantosa/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Two Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"verified\": false,\n",
      "  \"distance\": 0.8571385339546812,\n",
      "  \"threshold\": 0.68,\n",
      "  \"model\": \"VGG-Face\",\n",
      "  \"detector_backend\": \"opencv\",\n",
      "  \"similarity_metric\": \"cosine\",\n",
      "  \"facial_areas\": {\n",
      "    \"img1\": {\n",
      "      \"x\": 335,\n",
      "      \"y\": 108,\n",
      "      \"w\": 484,\n",
      "      \"h\": 484,\n",
      "      \"left_eye\": [\n",
      "        645,\n",
      "        290\n",
      "      ],\n",
      "      \"right_eye\": [\n",
      "        489,\n",
      "        301\n",
      "      ]\n",
      "    },\n",
      "    \"img2\": {\n",
      "      \"x\": 318,\n",
      "      \"y\": 259,\n",
      "      \"w\": 389,\n",
      "      \"h\": 389,\n",
      "      \"left_eye\": [\n",
      "        579,\n",
      "        401\n",
      "      ],\n",
      "      \"right_eye\": [\n",
      "        423,\n",
      "        395\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"time\": 1.32\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = DeepFace.verify(img1_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/Barron.png\",img2_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/TrumpMew1.png\")\n",
    "print(json.dumps(result,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set Pandas to display the full content without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing 1 image from a database (pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-11 10:29:40 - Searching /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Search.png in 7 length datastore\n",
      "24-10-11 10:29:41 - find function duration 0.8587932586669922 seconds\n",
      "[                                                                      identity  \\\n",
      "0  /Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/TrumpMew2.png   \n",
      "1     /Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/Trump1.png   \n",
      "2     /Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/Trump3.png   \n",
      "\n",
      "                                       hash  target_x  target_y  target_w  \\\n",
      "0  d8baf7c8783018470b47cfb9790eda1407a6aa23       183        93       346   \n",
      "1  f7589797d221e817c885a2abc2f36886a9536853       259       150       368   \n",
      "2  ba519763be81cdaf8ac687940685e5f0ac82db26       430       177       346   \n",
      "\n",
      "   target_h  source_x  source_y  source_w  source_h  threshold  distance  \n",
      "0       346       170        27       682       682       0.68  0.613812  \n",
      "1       368       170        27       682       682       0.68  0.665577  \n",
      "2       346       170        27       682       682       0.68  0.669155  ]\n"
     ]
    }
   ],
   "source": [
    "dfs = DeepFace.find(\n",
    "  img_path = \"/Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Search.png\",\n",
    "  db_path = \"/Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos\",\n",
    ")\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|██████████████▌              | 2/4 [00:02<00:02,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-11 10:29:55 - gender_model_weights.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/gender_model_weights.h5\n",
      "To: /Users/komangandikawirasantosa/.deepface/weights/gender_model_weights.h5\n",
      "100%|█████████████████████████████████████████| 537M/537M [11:16<00:00, 794kB/s]\n",
      "Action: race:  75%|██████████████████████▌       | 3/4 [11:22<05:11, 311.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-11 10:41:16 - race_model_single_batch.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/race_model_single_batch.h5\n",
      "To: /Users/komangandikawirasantosa/.deepface/weights/race_model_single_batch.h5\n",
      "100%|████████████████████████████████████████| 537M/537M [08:29<00:00, 1.05MB/s]\n",
      "Action: race: 100%|██████████████████████████████| 4/4 [19:57<00:00, 299.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"emotion\": {\n",
      "      \"angry\": 33.51637622811653,\n",
      "      \"disgust\": 4.3580137653810107e-07,\n",
      "      \"fear\": 0.2850894753315732,\n",
      "      \"happy\": 3.1951090790195565e-05,\n",
      "      \"sad\": 52.929583366488416,\n",
      "      \"surprise\": 0.00014337358324713128,\n",
      "      \"neutral\": 13.268777028845372\n",
      "    },\n",
      "    \"dominant_emotion\": \"sad\",\n",
      "    \"region\": {\n",
      "      \"x\": 318,\n",
      "      \"y\": 259,\n",
      "      \"w\": 389,\n",
      "      \"h\": 389,\n",
      "      \"left_eye\": [\n",
      "        579,\n",
      "        401\n",
      "      ],\n",
      "      \"right_eye\": [\n",
      "        423,\n",
      "        395\n",
      "      ]\n",
      "    },\n",
      "    \"face_confidence\": 0.93,\n",
      "    \"age\": 24,\n",
      "    \"gender\": {\n",
      "      \"Woman\": 0.002447343103995081,\n",
      "      \"Man\": 99.99755620956421\n",
      "    },\n",
      "    \"dominant_gender\": \"Man\",\n",
      "    \"race\": {\n",
      "      \"asian\": 69.5778704192793,\n",
      "      \"indian\": 3.010650179010608,\n",
      "      \"black\": 1.137457279866066,\n",
      "      \"white\": 17.95490021051166,\n",
      "      \"middle eastern\": 1.7966136057241433,\n",
      "      \"latino hispanic\": 6.522501972615483\n",
      "    },\n",
      "    \"dominant_race\": \"asian\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "objs = DeepFace.analyze(img_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-Recog/Photos/TrumpMew1.png\")\n",
    "print(json.dumps(objs,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-11 15:52:35 - Age model is just built\n",
      "24-10-11 15:52:37 - Gender model is just built\n",
      "24-10-11 15:52:37 - Emotion model is just built\n",
      "24-10-11 15:52:38 - VGG-Face is built\n",
      "24-10-11 15:52:44 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-11 15:52:48 - freezed\n",
      "24-10-11 15:52:53 - freeze released\n",
      "24-10-11 15:52:56 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi2.JPG\n",
      "24-10-11 15:53:00 - freezed\n",
      "24-10-11 15:53:05 - freeze released\n",
      "24-10-11 15:53:08 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-11 15:53:13 - freezed\n",
      "24-10-11 15:53:18 - freeze released\n",
      "24-10-11 15:53:21 - freezed\n",
      "24-10-11 15:53:26 - freeze released\n",
      "24-10-11 15:53:29 - Hello, /Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database/Andika/Andi1.JPG\n",
      "24-10-11 15:53:34 - freezed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/DeepFace.py:476\u001b[0m, in \u001b[0;36mstream\u001b[0;34m(db_path, model_name, detector_backend, distance_metric, enable_face_analysis, source, time_threshold, frame_threshold, anti_spoofing)\u001b[0m\n\u001b[1;32m    473\u001b[0m time_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(time_threshold, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    474\u001b[0m frame_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(frame_threshold, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 476\u001b[0m \u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_face_analysis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_face_analysis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deepface/modules/streaming.py:86\u001b[0m, in \u001b[0;36manalysis\u001b[0;34m(db_path, model_name, detector_backend, distance_metric, enable_face_analysis, source, time_threshold, frame_threshold, anti_spoofing)\u001b[0m\n\u001b[1;32m     84\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(source)  \u001b[38;5;66;03m# webcam\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     has_frame, img \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_frame:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DeepFace.stream(db_path=\"/Users/komangandikawirasantosa/Face-Rec/DeepFace-IPYNB/Database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
